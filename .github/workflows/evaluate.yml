name: Model Evaluation

on:
  workflow_run:
    workflows: ["Test Pipeline"]
    types: [completed]

jobs:
  evaluate:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Evaluate model
        run: |
          echo "Evaluating model..."
          echo '{"accuracy": 0.85, "threshold": 0.80}' > metrics.json

      - name: Check evaluation threshold
        run: |
          python -c "
          import json
          data = json.load(open('metrics.json'))
          if data['accuracy'] < data['threshold']:
              print('Model evaluation FAILED')
              exit(1)
          else:
              print('Model evaluation PASSED')
          "

      - name: Save evaluation metrics
        uses: actions/upload-artifact@v4
        with:
          name: model-metrics
          path: metrics.json
